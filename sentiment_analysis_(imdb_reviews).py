# -*- coding: utf-8 -*-
"""Sentiment Analysis (IMDB Reviews).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fAjZjF1EwA4dEa2fziHYJ4skGJgCSIZr
"""

!pip install gensim
# Import the gensim downloader api

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout, BatchNormalization, LSTM
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import gensim.downloader as api

#Load IMDB data
vocab_size = 10000
max_length = 200
(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)

print(f"Training samples: {X_train.shape[0]}")
print(f"Testing samples: {X_test.shape[0]}")

# Convert word indices back to raw text for TF-IDF
word_index = imdb.get_word_index()
reverse_word_index = {value: key for key, value in word_index.items()}
X_train_text = [' '.join([reverse_word_index.get(i - 3, '?') for i in seq]) for seq in X_train]
X_test_text = [' '.join([reverse_word_index.get(i - 3, '?') for i in seq]) for seq in X_test]

# TF-IDF Vectorization
tfidf_vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_text).toarray()
X_test_tfidf = tfidf_vectorizer.transform(X_test_text).toarray()

# Word2Vec preprocessing
X_train_w2v = pad_sequences(X_train, maxlen=max_length)
X_test_w2v = pad_sequences(X_test, maxlen=max_length)

# Load pre-trained Word2Vec and build embedding matrix with normalization
word2vec = api.load("word2vec-google-news-300")
embedding_dim = 300
embedding_matrix = np.zeros((vocab_size + 1, embedding_dim))
for word, i in word_index.items():
    if i < vocab_size:
        word_normalized = word.lower()  # Normalize to lowercase
        try:
            embedding_matrix[i + 1] = word2vec[word_normalized]
        except KeyError:
            pass

# Verify coverage and embeddings
covered = sum(1 for i in range(vocab_size) if np.any(embedding_matrix[i + 1]))
print(f"Word2Vec coverage after normalization: {covered / vocab_size:.2%}")
print("Embedding for 'the' (index 1):", embedding_matrix[1][:10], "...")  # Verify non-zero values

# Average Word2Vec embeddings for an alternative input (300D)
X_train_w2v_avg = np.mean([embedding_matrix[seq] for seq in X_train_w2v], axis=1)
X_test_w2v_avg = np.mean([embedding_matrix[seq] for seq in X_test_w2v], axis=1)

# Print number of samples
print(f"Number of training samples: {X_train_w2v.shape[0]}")
print(f"Number of testing samples: {X_test_w2v.shape[0]}")

# Categories
cats = ['Negative', 'Positive']

covered = sum(1 for i in range(vocab_size) if np.any(embedding_matrix[i + 1]))
print(f"Word2Vec coverage: {covered / vocab_size:.2%}")

print(embedding_matrix[1])  # Should be the embedding for "the" (index 1 in IMDB)
print(embedding_matrix[0])  # Should be all zeros (padding)

print(X_train_w2v[0][:10])  # First 10 tokens of the first review

# Function to build and train ANN
def build_and_train_ann(X_train, X_test, y_train, y_test, config_name,
                        use_dropout=False, use_weight_decay=False, use_batch_norm=False,
                        use_early_stopping=False, use_embedding=False, use_lstm=False, use_avg_w2v=False):


    model = Sequential()
    if use_embedding and not use_avg_w2v:
        # Use sequence input with Embedding layer
        model.add(Embedding(vocab_size + 1, embedding_dim, weights=[embedding_matrix],
                            input_length=max_length, trainable=True))
        if use_lstm:
            model.add(LSTM(128, return_sequences=False))  # Output (None, 128)
        else:
            model.add(Flatten())  # Output (None, 60000)
        model.add(Dense(128, activation='relu',
                        kernel_regularizer=tf.keras.regularizers.l2(0.001) if use_weight_decay else None))
    else:  # TF-IDF
        model.add(Dense(128, input_dim=X_train.shape[1], activation='relu',
                        kernel_regularizer=tf.keras.regularizers.l2(0.001) if use_weight_decay else None))

    if use_batch_norm:
        model.add(BatchNormalization())
    if use_dropout:
        model.add(Dropout(0.3))
    model.add(Dense(64, activation='relu',
                    kernel_regularizer=tf.keras.regularizers.l2(0.001) if use_weight_decay else None))
    if use_batch_norm:
        model.add(BatchNormalization())
    if use_dropout:
        model.add(Dropout(0.3))
    model.add(Dense(1, activation='sigmoid'))

    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    callbacks = []
    if use_early_stopping:
        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
        callbacks.append(early_stopping)

    history = model.fit(X_train, y_train, epochs=5, batch_size=32,
                        validation_data=(X_test, y_test), callbacks=callbacks, verbose=1)

    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
    y_pred_prob = model.predict(X_test, verbose=0)
    y_pred = (y_pred_prob > 0.5).astype(int).flatten()

    final_train_acc = history.history['accuracy'][-1]

    print(f"Final Training Accuracy: {final_train_acc:.4f}")
    print(f"Test Accuracy: {test_acc:.4f}")
    print("Classification Report:")
    print(classification_report(y_test, y_pred, target_names=cats))

    plt.figure(figsize=(12, 4))
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Val Accuracy')
    plt.title(f'{config_name} - Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title(f'{config_name} - Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.tight_layout()
    plt.show()

    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=cats, yticklabels=cats)
    plt.title(f'Confusion Matrix - {config_name}')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

    return final_train_acc, test_acc, y_pred, model

# Test configurations for TF-IDF and Word2Vec
configs = [
    ("Baseline TF-IDF", X_train_tfidf, X_test_tfidf, False, False, False, False, False),
    ("TF-IDF with Early Stopping", X_train_tfidf, X_test_tfidf, False, False, False, True, False),
    ("TF-IDF with Dropout", X_train_tfidf, X_test_tfidf, True, False, False, False, False),
    ("TF-IDF with Weight Decay", X_train_tfidf, X_test_tfidf, False, True, False, False, False),
    ("TF-IDF with Batch Norm", X_train_tfidf, X_test_tfidf, False, False, True, False, False),
    ("Baseline Word2Vec", X_train_w2v, X_test_w2v, False, False, False, False, True),
    ("Word2Vec with Early Stopping", X_train_w2v, X_test_w2v, False, False, False, True, True),
    ("Word2Vec with Dropout", X_train_w2v, X_test_w2v, True, False, False, False, True),
    ("Word2Vec with Weight Decay", X_train_w2v, X_test_w2v, False, True, False, False, True),
    ("Word2Vec with Batch Norm", X_train_w2v, X_test_w2v, False, False, True, False, True),
]

# Run all configurations and store results
#This reults with old configuration, which get unexpted results for two methods
results = {}
models = {}
for config_name, X_train_config, X_test_config, dropout, weight_decay, batch_norm, early_stopping, use_embedding in configs:
    train_acc, test_acc, y_pred, model = build_and_train_ann(
        X_train_config, X_test_config, y_train, y_test, config_name,
        use_dropout=dropout, use_weight_decay=weight_decay,
        use_batch_norm=batch_norm, use_early_stopping=early_stopping,
        use_embedding=use_embedding
    )
    results[config_name] = {'train_accuracy': train_acc, 'test_accuracy': test_acc, 'y_pred': y_pred}
    models[config_name] = model

# Print summary of results
print("\n=== Summary of Results ===")
for config_name, metrics in results.items():
    print(f"{config_name}: Train Acc = {metrics['train_accuracy']:.4f}, Test Acc = {metrics['test_accuracy']:.4f}")

from tabulate import tabulate

# Print Table ANN Performance Across Configurations
print("\nTable: ANN Performance Across Configurations")
table_data = []
for config_name, result in results.items():
    table_data.append([
        config_name,
        f"{result['train_accuracy']:.4f}",
        f"{result['test_accuracy']:.4f}"
    ])

headers = ["Configuration", "Training Accuracy", "Test Accuracy"]
print(tabulate(table_data, headers=headers, tablefmt="grid"))

# Add Grouped Bar Plot
plt.figure(figsize=(12, 6))
bar_width = 0.35
index = np.arange(len(results))

train_accuracies = [result['train_accuracy'] for result in results.values()]
test_accuracies = [result['test_accuracy'] for result in results.values()]

plt.bar(index, train_accuracies, bar_width, label='Training Accuracy', color='skyblue')
plt.bar(index + bar_width, test_accuracies, bar_width, label='Test Accuracy', color='salmon')

plt.xlabel('Configuration', fontsize=12)
plt.ylabel('Accuracy', fontsize=12)
plt.title('Training vs Test Accuracies Across Configurations', fontsize=14)
plt.xticks(index + bar_width / 2, list(results.keys()), rotation=45, ha='right')
plt.legend()
plt.tight_layout()
plt.show()

"""**Results Word2Vec: 0.5–0.69 (Unexpected)**

To improve accuracy, the model was re-trained with updated configurations:

Epochs: Reduced from 10 to 5

Patience: Reduced from 5 to 3

Dropout: Adjusted from 0.5 to 0.3

**Impact of updates:**

Word2Vec accuracy improved from 0.5–0.69 to 0.83–0.85

TF accuracy still same range 0.85–0.87
"""

# Test configurations for Word2Vec
configs = [

    ("Baseline Word2Vec", X_train_w2v, X_test_w2v, False, False, False, False, True),
    ("Word2Vec with Early Stopping", X_train_w2v, X_test_w2v, False, False, False, True, True),
    ("Word2Vec with Dropout", X_train_w2v, X_test_w2v, True, False, False, False, True),
    ("Word2Vec with Weight Decay", X_train_w2v, X_test_w2v, False, True, False, False, True),
    ("Word2Vec with Batch Norm", X_train_w2v, X_test_w2v, False, False, True, False, True),
]
# Run all configurations and store results
results = {}
models = {}
for config_name, X_train_config, X_test_config, dropout, weight_decay, batch_norm, early_stopping, use_embedding in configs:
    train_acc, test_acc, y_pred, model = build_and_train_ann(
        X_train_config, X_test_config, y_train, y_test, config_name,
        use_dropout=dropout, use_weight_decay=weight_decay,
        use_batch_norm=batch_norm, use_early_stopping=early_stopping,
        use_embedding=use_embedding
    )
    results[config_name] = {'train_accuracy': train_acc, 'test_accuracy': test_acc, 'y_pred': y_pred}
    models[config_name] = model

# Print summary of results
print("\n=== Summary of Results ===")
for config_name, metrics in results.items():
    print(f"{config_name}: Train Acc = {metrics['train_accuracy']:.4f}, Test Acc = {metrics['test_accuracy']:.4f}")

# Test configurations for TF-IDF
configs = [

    ("Baseline TF-IDF", X_train_tfidf, X_test_tfidf, False, False, False, False, False),
    ("TF-IDF with Early Stopping", X_train_tfidf, X_test_tfidf, False, False, False, True, False),
    ("TF-IDF with Dropout", X_train_tfidf, X_test_tfidf, True, False, False, False, False),
    ("TF-IDF with Weight Decay", X_train_tfidf, X_test_tfidf, False, True, False, False, False),
    ("TF-IDF with Batch Norm", X_train_tfidf, X_test_tfidf, False, False, True, False, False)
]
# Run all configurations and store results
results = {}
models = {}
for config_name, X_train_config, X_test_config, dropout, weight_decay, batch_norm, early_stopping, use_embedding in configs:
    train_acc, test_acc, y_pred, model = build_and_train_ann(
        X_train_config, X_test_config, y_train, y_test, config_name,
        use_dropout=dropout, use_weight_decay=weight_decay,
        use_batch_norm=batch_norm, use_early_stopping=early_stopping,
        use_embedding=use_embedding
    )
    results[config_name] = {'train_accuracy': train_acc, 'test_accuracy': test_acc, 'y_pred': y_pred}
    models[config_name] = model

# Print summary of results
print("\n=== Summary of Results TF-IDF ===")
for config_name, metrics in results.items():
    print(f"{config_name}: Train Acc = {metrics['train_accuracy']:.4f}, Test Acc = {metrics['test_accuracy']:.4f}")

print("X_train_w2v shape:", X_train_w2v.shape)  # Should be (25000, 200)
print("y_train shape:", y_train.shape)  # Should be (25000,)
model.summary()

print(f"Training samples: {len(X_train)}, Test samples: {len(X_test)}")
print(f"Unique labels in y_train: {np.unique(y_train)}")
print(f"Unique labels in y_test: {np.unique(y_test)}")



import matplotlib.pyplot as plt
from matplotlib.patches import Patch

# Data from the table
configurations = [
    "Baseline",
    "Early Stopping",
    "Dropout",
    "Weight Decay",
    "Batch Norm"
]

test_acc_w2v = [0.8344, 0.8578, 0.8444, 0.8326, 0.8335]  # Test Acc for W2V
test_acc_tfidf = [0.8613, 0.8796, 0.8641, 0.8751, 0.8530]  # Test Acc for TF-IDF

# Combine method names for the x-axis labels
methods_w2v = [f"{config}\n(W2V)" for config in configurations]
methods_tfidf = [f"{config}\n(TF-IDF)" for config in configurations]
all_labels = []
for w2v, tfidf in zip(methods_w2v, methods_tfidf):
    all_labels.append(w2v)
    all_labels.append(tfidf)

# Combine test accuracies for plotting
all_test_acc = []
for w2v_acc, tfidf_acc in zip(test_acc_w2v, test_acc_tfidf):
    all_test_acc.append(w2v_acc)
    all_test_acc.append(tfidf_acc)

# Colors for W2V and TF-IDF
colors = []
for _ in range(len(configurations)):
    colors.append('#99FF99')  # W2V
    colors.append('#66B2FF')  # TF-IDF

# Create the bar plot
plt.figure(figsize=(12, 6))
bars = plt.bar(all_labels, all_test_acc, color=colors)
plt.xlabel('Configuration')
plt.ylabel('Test Accuracy')
plt.title('Test Accuracy Comparison: Word2Vec vs. TF-IDF')
plt.xticks(rotation=45, ha='right')
plt.ylim(0, 1)

# Add legend
legend_elements = [
    Patch(facecolor='#99FF99', label='Word2Vec'),
    Patch(facecolor='#66B2FF', label='TF-IDF')
]
plt.legend(handles=legend_elements, title='Embedding Method')

plt.tight_layout()
plt.show()

